{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6d95b5",
   "metadata": {},
   "source": [
    "## **1. IMPORTS Y CONFIGURACI√ìN**\n",
    "Importamos las librer√≠as necesarias para el procesamiento de im√°genes, redes neuronales y entrenamiento distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e328c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.torch.distributor import TorchDistributor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e80cf",
   "metadata": {},
   "source": [
    "## **2. FUNCI√ìN DE ENTRENAMIENTO DISTRIBUIDO**\n",
    "Esta funci√≥n entrena un modelo ResNet18 de manera distribuida usando PyTorch y Spark.\n",
    "Se hace uso de AMP (Automatic Mixed Precision) para optimizar el rendimiento en GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef9d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn():\n",
    "    \"\"\"\n",
    "    Esta funci√≥n entrena un modelo ResNet18 de manera distribuida usando PyTorch y Spark.\n",
    "    Se hace uso de AMP (Automatic Mixed Precision) para optimizar el rendimiento en GPUs.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.distributed as dist\n",
    "    from torchvision import transforms, datasets, models\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.utils.data.distributed import DistributedSampler\n",
    "    import io, os\n",
    "\n",
    "    print(\"=== DISTRIBUTED RESNET18 TRAINING (AMP + SHARDING) ===\")\n",
    "\n",
    "    # ========================================\n",
    "    # A. METADATOS DISTRIBUIDOS\n",
    "    # ========================================\n",
    "\n",
    "    # Informaci√≥n del proceso distribuido, como el rank (ID del worker) y el tama√±o total del mundo (n√∫mero de workers)\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    print(f\"[Worker {rank}] World size: {world_size}\")\n",
    "\n",
    "    # Definimos la ruta del dataset, que se encuentra en un sistema de archivos distribuido (NFS).\n",
    "    dataset_path = \"/mnt/spark_data/DATASET-RUIDO\"\n",
    "    print(f\"[Worker {rank}] Dataset path: {dataset_path}\")\n",
    "\n",
    "    # ========================================\n",
    "    # B. TRANSFORMACIONES DE IM√ÅGENES\n",
    "    # ========================================\n",
    "\n",
    "    # Definimos las transformaciones que se aplicar√°n a las im√°genes de entrenamiento.\n",
    "    # Estas incluyen el redimensionamiento, la normalizaci√≥n y la aleatorizaci√≥n de las im√°genes.\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # ============================\n",
    "    # C. CARGA DE LOS DATOS\n",
    "    # ============================\n",
    "\n",
    "    # Cargamos el dataset usando la clase ImageFolder de PyTorch y aplicamos las transformaciones definidas anteriormente.\n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=train_tf)\n",
    "\n",
    "    # ============================\n",
    "    # D. SAMPLER DISTRIBUIDO\n",
    "    # ============================\n",
    "\n",
    "    # Utilizamos un sampler distribuido para que cada worker cargue su parte del dataset de manera eficiente.\n",
    "    sampler = DistributedSampler(\n",
    "        dataset,\n",
    "        num_replicas=world_size,  # N√∫mero total de workers\n",
    "        rank=rank,  # ID del worker actual\n",
    "        shuffle=True  # Mezclar los datos\n",
    "    )\n",
    "\n",
    "    # Creamos un DataLoader que usar√° este sampler distribuido.\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,  # Tama√±o del batch\n",
    "        sampler=sampler,\n",
    "        num_workers=4,  # N√∫mero de workers para cargar los datos\n",
    "        pin_memory=True  # Mejor rendimiento en GPUs\n",
    "    )\n",
    "\n",
    "    print(f\"[Worker {rank}] Total images loaded: {len(dataset)}\")\n",
    "\n",
    "    # ================================\n",
    "    # E. CONFIGURACI√ìN DEL DISPOSITIVO\n",
    "    # ================================\n",
    "\n",
    "    # Verificamos si hay una GPU disponible y configuramos el dispositivo donde se entrenar√° el modelo.\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Worker {rank}] Training on: {device}\")\n",
    "\n",
    "    # ============================\n",
    "    # F. MODELO PREENTRENADO\n",
    "    # ============================\n",
    "\n",
    "    # Cargamos un modelo preentrenado ResNet18 y reemplazamos la √∫ltima capa para adaptarlo a nuestro problema (2 clases).\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)  # Adaptamos la capa final\n",
    "    model = model.to(device)  # Movemos el modelo al dispositivo (GPU o CPU)\n",
    "    model.train()  # Ponemos el modelo en modo de entrenamiento\n",
    "\n",
    "    # ================================\n",
    "    # G. CRITERIO, OPTIMIZADOR Y AMP\n",
    "    # ================================\n",
    "\n",
    "    # Definimos la funci√≥n de p√©rdida y el optimizador.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Utilizamos el GradScaler para mejorar el rendimiento en GPUs con AMP (Precisi√≥n Mixta Autom√°tica).\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # ================================\n",
    "    # H. BUCLE DE ENTRENAMIENTO\n",
    "    # ================================\n",
    "\n",
    "    # Definimos el n√∫mero de √©pocas para entrenar el modelo.\n",
    "    EPOCHS = 3\n",
    "    print(f\"[Worker {rank}] Starting training for {EPOCHS} epochs\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Establecemos la √©poca para el sampler distribuido.\n",
    "        sampler.set_epoch(epoch)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Bucle de entrenamiento para cada batch\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Usamos AMP para entrenamiento con precisi√≥n mixta\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation con AMP\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Imprimimos el progreso del entrenamiento\n",
    "        print(f\"[Worker {rank}] Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    print(f\"[Worker {rank}] Training finished!\")\n",
    "\n",
    "    # ============================\n",
    "    # I. DEVOLVER EL MODELO\n",
    "    # ============================\n",
    "\n",
    "    # Solo el worker 0 (primer worker) guarda y devuelve el modelo entrenado.\n",
    "    if rank == 0:\n",
    "        buffer = io.BytesIO()\n",
    "        torch.save(model.state_dict(), buffer)\n",
    "        buffer.seek(0)\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2e288",
   "metadata": {},
   "source": [
    "## **3. CONFIGURACI√ìN DE SPARK**\n",
    "Creamos una sesi√≥n de Spark configurada para el entrenamiento distribuido con GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760a8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/22 19:18:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# SPARK CONFIG\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BrainTumor-ResNet18-Distributed-IPYNB\")\n",
    "    .master(\"spark://100.108.67.1:7077\")\n",
    "    .config(\"spark.executor.instances\", \"2\")\n",
    "    .config(\"spark.executor.resource.gpu.amount\", \"1\")\n",
    "    .config(\"spark.executor.resource.gpu.discoveryScript\", \"/usr/local/bin/get-gpus.sh\")\n",
    "    .config(\"spark.task.resource.gpu.amount\", \"1\")\n",
    "    .config(\"spark.executorEnv.NCCL_SOCKET_IFNAME\", \"tailscale0\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eff438",
   "metadata": {},
   "source": [
    "Inicializamos Spark y lo dejamos listo para ejecutar el entrenamiento distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036f9b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://100.108.67.1:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BrainTumor-ResNet18-Distributed-IPYNB</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x78d7b00a0dc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7ca8a",
   "metadata": {},
   "source": [
    "\n",
    "## **4. EJECUCI√ìN Y GUARDADO DEL MODELO DISTRIBUIDO**\n",
    "Imprimimos mensaje para indicar el inicio del entrenamiento distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e878939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching distributed training with AMP + SHARDING + 2 GPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started distributed training with 2 executor processes\n",
      "=== DISTRIBUTED RESNET18 TRAINING (AMP + SHARDING) ===              (0 + 2) / 2]\n",
      "[Worker 0] World size: 2\n",
      "[Worker 0] Dataset path: /mnt/spark_data/DATASET-RUIDO\n",
      "=== DISTRIBUTED RESNET18 TRAINING (AMP + SHARDING) ===\n",
      "[Worker 1] World size: 2\n",
      "[Worker 1] Dataset path: /mnt/spark_data/DATASET-RUIDO\n",
      "[Worker 0] Total images loaded: 5000                                (0 + 2) / 2]\n",
      "[Worker 0] Training on: cuda\n",
      "/tmp/ipykernel_218538/3021167563.py:101: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "[Worker 0] Starting training for 3 epochs\n",
      "/tmp/ipykernel_218538/3021167563.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "[Worker 0] Epoch 1/3 - Loss: 13.4124\n",
      "[Worker 0] Epoch 2/3 - Loss: 6.0668\n",
      "[Worker 0] Epoch 3/3 - Loss: 1.9728                                 (0 + 2) / 2]\n",
      "[Worker 0] Training finished!\n",
      "[Worker 1] Total images loaded: 5000\n",
      "[Worker 1] Training on: cuda\n",
      "/tmp/ipykernel_218538/3021167563.py:101: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "[Worker 1] Starting training for 3 epochs\n",
      "/tmp/ipykernel_218538/3021167563.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "[Worker 1] Epoch 1/3 - Loss: 14.0739                                (0 + 2) / 2]\n",
      "[Worker 1] Epoch 2/3 - Loss: 3.5299                                 (0 + 2) / 2]\n",
      "[Worker 1] Epoch 3/3 - Loss: 1.4003\n",
      "[Worker 1] Training finished!\n",
      "Finished distributed training with 2 executor processes                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado correctamente en: /home/piero/brain_resnet18.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Launching distributed training with AMP + SHARDING + 2 GPUs...\")\n",
    "\n",
    "# Usamos el distribuidor de PySpark para ejecutar la funci√≥n de entrenamiento en dos procesos (uno por cada GPU).\n",
    "model_bytes = TorchDistributor(\n",
    "    num_processes=2,  # N√∫mero de procesos a usar (uno por GPU)\n",
    "    local_mode=False,  # Ejecutar en un cluster distribuido\n",
    "    use_gpu=True  # Usar GPUs para el entrenamiento\n",
    ").run(train_fn)\n",
    "\n",
    "# Si el modelo se entren√≥ correctamente y se devolvi√≥, lo guardamos en un archivo local.\n",
    "if model_bytes is not None:\n",
    "    # Ruta donde se guardar√° el modelo entrenado.\n",
    "    out_path = \"/home/piero/brain_resnet18.pt\"\n",
    "    \n",
    "    # Abrimos el archivo en modo escritura binaria y guardamos los bytes del modelo.\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(model_bytes)\n",
    "    \n",
    "    # Imprimimos una confirmaci√≥n indicando que el modelo se guard√≥ correctamente.\n",
    "    print(f\"Modelo guardado correctamente en: {out_path}\")\n",
    "else:\n",
    "    # Si el worker secundario no devuelve el modelo, mostramos un mensaje de error.\n",
    "    print(\"Worker secundario: no devuelve modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9d03e",
   "metadata": {},
   "source": [
    "## **5. REGISTRAR EL EXPERIMENTO EN MLFLOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f647e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/pytorch-env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/pytorch-env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=6b16b3ed-cd23-4345-b005-36ff8d963e4f&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=7bffd1fbbee7c3758a08393e9b05a8b5860d586823cf8b7d80485d1d17d02ff2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as picantitoDev\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as picantitoDev\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"picantitoDev/percepcion-proyecto\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"picantitoDev/percepcion-proyecto\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository picantitoDev/percepcion-proyecto initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository picantitoDev/percepcion-proyecto initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/22 19:24:04 INFO mlflow.tracking.fluent: Experiment with name 'ResNet18-Distributed-AMP' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/b4b56f5dabe94db9a5cf1af5119248d6', creation_time=1763857444386, experiment_id='0', last_update_time=1763857444386, lifecycle_stage='active', name='ResNet18-Distributed-AMP', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "dagshub.init(\n",
    "    repo_owner='picantitoDev',\n",
    "    repo_name='percepcion-proyecto',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/picantitoDev/percepcion-proyecto.mlflow\")\n",
    "mlflow.set_experiment(\"ResNet18-Distributed-AMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39597d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando en MLflow...\n",
      "Modelo registrado en MLflow correctamente.\n",
      "Registering model 'ResNet18' from runs:/7caba809aabf4de6b9716fc2eea9c8cf/model ...\n",
      "Created new registered model: ResNet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/22 19:45:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered successfully!\n",
      "Model version: 1\n",
      "Model details: <ModelVersion: aliases=[], creation_timestamp=1763858735162, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1763858735162, metrics=None, model_id=None, name='ResNet18', params=None, run_id='7caba809aabf4de6b9716fc2eea9c8cf', run_link='', source='runs:/7caba809aabf4de6b9716fc2eea9c8cf/model', status='READY', status_message=None, tags={}, user_id='', version='1'>\n",
      "üèÉ View run angry-moth-625 at: https://dagshub.com/picantitoDev/percepcion-proyecto.mlflow/#/experiments/0/runs/7caba809aabf4de6b9716fc2eea9c8cf\n",
      "üß™ View experiment at: https://dagshub.com/picantitoDev/percepcion-proyecto.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "if model_bytes is not None:\n",
    "    print(\"Registrando en MLflow...\")\n",
    "\n",
    "    buffer = io.BytesIO(model_bytes)\n",
    "    state_dict = torch.load(buffer, map_location=\"cpu\")\n",
    "\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        # PARAMS\n",
    "        mlflow.log_params({\n",
    "            \"batch_size\": 32,\n",
    "            \"epochs\": 3,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"lr\": 1e-4,\n",
    "            \"model\": \"ResNet18\",\n",
    "            \"distributed_world_size\": 2,\n",
    "            \"amp\": True,\n",
    "        })\n",
    "\n",
    "        mlflow.log_metric(\"final_loss\", 0)\n",
    "\n",
    "        # FIX: REMOVE PREVIOUS MODEL FOLDER\n",
    "        import shutil, os\n",
    "        if os.path.exists(\"model\"):\n",
    "            shutil.rmtree(\"model\")\n",
    "\n",
    "        # LOG MODEL\n",
    "        mlflow.pytorch.save_model(model, path=\"model\")\n",
    "        mlflow.log_artifacts(\"model\", artifact_path=\"model\")\n",
    "\n",
    "        print(\"Modelo registrado en MLflow correctamente.\")\n",
    "        \n",
    "        # ==========================================\n",
    "        # REGISTER THE MODEL IN DAGSHUB MODEL REGISTRY\n",
    "        # ==========================================\n",
    "        from mlflow import MlflowClient\n",
    "        \n",
    "        run_id = run.info.run_id\n",
    "        model_name = \"ResNet18\"\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        \n",
    "        client = MlflowClient()\n",
    "        \n",
    "        print(f\"Registering model '{model_name}' from {model_uri} ...\")\n",
    "        \n",
    "        try:\n",
    "            registered_model = client.create_registered_model(model_name)\n",
    "            print(f\"Created new registered model: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model {model_name} already exists, creating new version...\")\n",
    "        \n",
    "        # Create a new version\n",
    "        model_version = client.create_model_version(\n",
    "            name=model_name,\n",
    "            source=model_uri,\n",
    "            run_id=run_id\n",
    "        )\n",
    "        \n",
    "        print(\"Model registered successfully!\")\n",
    "        print(f\"Model version: {model_version.version}\")\n",
    "        print(\"Model details:\", model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7abc24",
   "metadata": {},
   "source": [
    "## **6. DETENER LA SESI√ìN DE SPARK**\n",
    "\n",
    "\n",
    "Finalmente, detenemos la sesi√≥n de Spark para liberar los recursos del cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b33362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
